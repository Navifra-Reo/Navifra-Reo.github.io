---
title:  "Perceptron"
excerpt: "Deep Learning Summary"

categories:
  - A.I

tags:
  - [deep learning, machine learning, AI, School Summary]

toc: true
toc_sticky: true
layout: post
use_math: true
 
date: 2022-09-27
last_modified_at: 2022-09-27
---

# 3.1 인공 신경망

### **신경망의 특성**

- 생물학적 신경망의 중추신경계인 인간의 뇌가 문제를 처리하는 방식을 모방한 모형
- 각 노드가 인공 뉴런(퍼셉트론)으로 구성
- <span style="color:orange">하나이상의 은닉층 포함</span>
- 신경망 내부의 노드들이 연결되어 높은 연결성을 나타낸다. 이때 노드간 연결 강도는 가중치
- 일반적으로 신경망은 완전연결
  - 인접한 층 사이의 노드끼리 모두 연결
- 훈련에 <span style="color:gold">역전파 알고리즘</span> 사용

### **역전파 알고리즘**

- <span style="color:skyblue">오차(에러)를</span> 본래 진행방향과 <span style="color:gold">반대방향으로 전파</span>시켜 가중치를 조정하는 방법

- **전방향 단계**

  신경망 가중치 고정. 입력신호는 출력에 도달할 때까지 층별로 전파

- **역뱡향 단계**

  신경망 출력을 목표출력과 비교하여 오차신호 생성

  오차신호는 역방향으로 층별로 전파하여 신경망의 가중치를 연속적으로 조정

### **인공 뉴런/Perceptron**

- 생물학적 뉴런의 정보처리 기능을 추상화한 신경망 모형
- 각 입력에 가중치를 곱하고 합한 값을 활성함수 $\sigma$에 통과시켜 임계값을 적용하여 다음 노드의 입력값으로 보낸다

  > $ \omicron = \sigma(\displaystyle\sum_{i=1}^{d}{W_ix_i}+b) $

  ![인공뉴런 사진](/assets/img/%EC%9D%B8%EA%B3%B5%EB%89%B4%EB%9F%B0.png)

### **신경망의 종류**

- 전방<sup>feed forward</sup>,순환<sup>recurrent</sup> 신경망
  - 노드간 연결에서 순환이 발생 여부에 따라 전방, 순환 신경망으로 분류
  
    ![전방, 순환 신경망](/assets/img/%EC%A0%84%EB%B0%A9%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D.png)
- 얕은,깊은 신경망
  - 은닉층의 개수에 따른 신경망 분류

    ![얕은, 깊은 신경망](/assets/img/%EA%B9%8A%EC%9D%B4%EC%97%90%EB%94%B0%EB%A5%B8%20%EC%8B%A0%EA%B2%BD%EB%A7%9D.png)
- 결정 신경망
  - 신경망 구성요소(노드, 가중치 등)의 값들이 고정되어 입력에 따른 출력이 고정되어 있는 신경망
- 스토캐스틱 신경망
  - 입력에 따른 출력이 확률적으로 결정되기 때문에 매번 결과가 다르게 나오는 신경망
  - Drop out(=랜덤한 인공 뉴런을 제거)등의 기법으로 구현
  ![drop out 예시](/assets/img/dropout.png)

# 3.2 **다층 퍼셉트론**

### **퍼셉트론의 한계**

- 선형분류기라는 한계를 가짐
- 아래 사진과 같이 선형분리에 적합하지 않은 문제들이 존재
  ![선형분리문제](/assets/img/%EC%84%A0%ED%98%95%EB%B6%84%EB%A6%AC.png)
- 선형분리가 되지 않는 문제를 퍼셉트론 사이의 결합을 통해 해결

### **다층 퍼셉트론의 핵심 아이디어**

- 은닉층
- 시그모이드와 같은 비선형 활성함수
- 오류 역전파 알고리즘

### **특징공간 변환**

- 다수의 퍼셉트론을 합성하여 특징공간을 변환하여 선형분리

### **활성함수**

- 퍼셉트론에서 입력신호의 <span style="color:orange">활성값<sup>가중합을 의미</sup>을 출력 신호로 변환</span>하는 함수
- 주로 $\tau$로 표현
- **공간분할**
  - 활성함수는 입력값을 활성화<sup>작은것은 작게, 큰것은 크게</sup> 하여 공간을 분할해 출력값을 통해 의사를 결정
  ![선형분리문제](/assets/img/%EA%B3%B5%EA%B0%84%20%EB%B6%84%ED%95%A0.png)
  
- **활성 함수 종류**
  - 시그모이드 함수는 $\sigma$로 표현

- 비선형 활성함수를 사용하는 이유
  - 중간중간 비선형연산(ReLU등)을 사용하는 이유는 선형 연산으로만 신경망을 쌓으면 신경망이 하나로 함축될 수 있어 여러개의 층으로 쌓는 이유가 없음. 이때 이것을 신경망이 무너진다?라고 표현